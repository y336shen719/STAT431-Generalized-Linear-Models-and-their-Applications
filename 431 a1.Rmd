---
title: "431 assignment1"
author: "Yiming Shen 20891774"
date: "28/09/2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1
```{R}
library(ALSM)
data(GroceryRetailer)
str(GroceryRetailer)
```
### (a)
```{R}
model <- lm(y ~ x1 + x2 + x3, data = GroceryRetailer)
summary(model)
confint(model)
```
Based on the ouput, we find the estimated regression equation is:
y_hat = 4150 + 0.0007871*x1 + (-13.17)*x2 + 623.6*x3

Interpretation:
beta1_hat = 0.0007871: when other variables are kept unchanged, 
as the number of cases shipped increase one, the average of total labour hours 
is estimated to increase 0.0007871 hours.
95% C.I. for beta1_hat is [5.409544e-05, 0.001520065]

beta2_hat = -13.17: when other variables are kept unchanged,
as the indirect costs of the total labour hours as a percentage increase one
unit, the average of total labour hours is estimated to decrease 13.17 hours.
95% C.I. for beta2_hat is [-59.59506, 33.26302]

beta3_hat = 623.6: when other variables are kept unchanged,
compared with a week without holiday, the average of total labour hours in
the week with a holiday is estimated to increase 623.6 hourss.
95% C.I. for beta3_hat is [497.6064, 749.5025]


### (b)
```{R}
# method 1
plot(fitted(model), residuals(model), xlab="Fitted Value", ylab="Residuals",
     main = "Plot of Residuals vs. Fitted Value")
```
Based on the plot, we find that almost all points are spread within a constant
band, except a few outliers, which shows the constant variance of model assumptions.

```{r}
# method 2
plot(GroceryRetailer$x1, residuals(model), xlab="Number of cases shipped",
     ylab="Residuals", 
     main="Plot of x1 (Number of cases shipped) vs. Residuals")

plot(GroceryRetailer$x2, residuals(model), 
     xlab="Indirect costs of total labour hours as a percentage",
     ylab="Residuals", 
     main="Plot of x2 (Indirect costs a percentage) vs. Residuals")

plot(GroceryRetailer$x3, residuals(model), xlab="Holiday Indicator",
     ylab="Residuals", 
     main="Plot of x3 (Holiday Indicator) vs. Residuals")
```

Based on the plot, we find that there exists some linear relationship between
x1 and residuals and same for x2 and x3, which shows the linearity of model
assumptions.



```{R}
# method 3
qqnorm(residuals(model))
qqline(residuals(model))
```

Based on the QQplot, we find that all points are distributed along the line,
which shows the normality of model assumptions.

In conclusion, based on 3 methods, we find that all assumptions appear to be
met.

### (c)
```{r}
mean1 <- mean(GroceryRetailer$x1)
mean2 <- mean(GroceryRetailer$x2)
# since no holiday, so x3=0
predict(model,newdata = data.frame(x1=mean1,x2=mean2,x3=0),
        interval = "confidence", level = 0.95)
```

Based on the output, we find that the estimate of the mean total labour hours
is 4291.09 hours. And the corresponding 95% C.I. is [4248.576, 4333.603]


### (d)
```{R}
model2 <- lm(y ~ x1*x3 + x2*x3, data = GroceryRetailer)
# ANOVA test
anova(model,model2)
```

Based on the output, we find the p-value of ANOVA test is 0.4417
Since the significance level is 0.05
p-value > 0.05, we do not reject null hypothesis, which shows that there is no
association.


\newpage
## Question 2

### (c)
```{r}
# when 1000 sample size , n=20, pie = 0.5
result <- c()
for (i in 1:1000){
n <- 20
y <- rbinom(n, size=1, prob=0.5)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

```{r}
# when n = 100
result <- c()
for (i in 1:1000){
n <- 100
y <- rbinom(n, size=1, prob=0.5)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```


```{r}
# when n = 1000
result <- c()
for (i in 1:1000){
n <- 1000
y <- rbinom(n, size=1, prob=0.5)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

Comment: After simulating at n=20;100;1000, I find that with the increase of
size n (from n=20 to n=100 to n=1000), the estimate of probability of rejecting
the null hypothesis get closer to level 0.05



### (d)
```{r}
# when 1000 sample size , n=20, pie = 0.6
result <- c()
for (i in 1:1000){
n <- 20
y <- rbinom(n, size=1, prob=0.6)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

```{r}
# when n = 100, pie = 0.6
result <- c()
for (i in 1:1000){
n <- 100
y <- rbinom(n, size=1, prob=0.6)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

```{r}
# when n=1000, pie = 0.6
result <- c()
for (i in 1:1000){
n <- 1000
y <- rbinom(n, size=1, prob=0.6)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

```{r}
# when 1000 sample size , n=20, pie = 0.8
result <- c()
for (i in 1:1000){
n <- 20
y <- rbinom(n, size=1, prob=0.8)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

```{r}
# when n = 100, pie = 0.8
result <- c()
for (i in 1:1000){
n <- 100
y <- rbinom(n, size=1, prob=0.8)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

```{r}
# when n=1000, pie = 0.8
result <- c()
for (i in 1:1000){
n <- 1000
y <- rbinom(n, size=1, prob=0.8)
likelihood_ratio_stat <- (-2)*(sum(y)*log(0.5)+(n-sum(y))*log(1-0.5)-
                                 sum(y)*log(mean(y))-(n-sum(y))*log(1-mean(y)))
p_value <- 1 - pchisq(likelihood_ratio_stat,1)
result[i] <- p_value < 0.05
}
mean(result)
```

Table and Summary: please see the attach separate PDF

\newpage
## Question 4
### (b)

y <- c(118,58,42,35,27,25,21,19,18)
u <- c(5,10,15,20,30,40,60,80,100)
x <- log(u)

Score_element <- function(beta_element,y) {sum(y)/beta_element - length (y)}
Score <- function(beta,y) {sapply(beta,FUN=Score_element)}

Info_element <- function(beta_element,y) {sum(y)/(beta_element^2)}
Info <- function(beta,y) {sapply(beta, FUN=Info_element)}

beta.old <- c(0,0,0)
beta.new <- c(1,0,2)

track = c(beta.new , Score(beta.new , y))
while( (beta.new[1]-beta.old[1])^2 + (beta.new[2]-beta.old[2])^2 + (beta.new[3]-beta.old[3])^2 > 10^{-3} )
{
  beta.old = beta.new
  beta.new = beta.old + Score(beta.old,y) %*% solve(Info(beta.old,y))
  track = rbind(track,c(beta.new, Score(beta.new, y)))
}
track

